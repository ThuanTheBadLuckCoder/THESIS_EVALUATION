{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG ChatBot Response Evaluation\n",
    "\n",
    "## Objective\n",
    "Comprehensively evaluate and compare three different RAG ChatBot responses to the same prompt using multiple evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Can you generate an HTML code using TailwindCSS that creates a responsive feature section with a main heading, a short description, and three feature cards? Each card should include an SVG icon, a title, a description, and a list of related topics (like Computers, Health, Reference). The layout should use a grid system and flexbox for alignment, styled entirely with Tailwind utility classes. It should have a clean, modern design and be fully responsive. This component should be static, with no JavaScript interactivity.\n",
      "\n",
      "Responses:\n",
      "\n",
      "Response A:\n",
      "Sure! Here's a clean, modern, and fully responsive Feature Section built with HTML and TailwindCSS.\n",
      "It includes a main heading, a short description, and three feature cards laid out using a grid and flexbox:\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "<meta charset=\"UTF-8\" />\n",
      "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
      "<title>Feature Section</title>\n",
      "<script src=\"https://cdn.tailwindcss.com\"></script>\n",
      "</head>\n",
      "<body class=\"bg-gray-50 text-gray-800\">\n",
      "<section class=\"max-w-7xl mx-auto px-6 py-16\">\n",
      "<div class=\"text-center mb-12\">\n",
      "<h2 class=\"text-4xl font-bold mb-4\">Discover Our Features</h2>\n",
      "<p class=\"text-gray-600 max-w-2xl mx-auto\">\n",
      "Explore the tools and capabilities that help you stay productive and ahead of the curve.\n",
      "</p>\n",
      "</div>\n",
      "\n",
      "<div class=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8\">\n",
      "<!-- Feature Card 1 -->\n",
      "<div class=\"bg-white rounded-2xl shadow-md p-6 flex flex-col\">\n",
      "<div class=\"flex items-center justify-center w-16 h-16 bg-blue-100 rounded-full mb-4\">\n",
      "<!-- Example SVG: Computer Icon -->\n",
      "<svg class=\"w-8 h-8 text-blue-600\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\"\n",
      "viewBox=\"0 0 24 24\">\n",
      "<path stroke-linecap=\"round\" stroke-linejoin=\"round\"\n",
      "d=\"M9.75 17h4.5m-9-2.25h13.5a.75.75 0 0 0 .75-.75V5.25a.75.75 0 0 0-.75-.75H5.25a.75.75 0 0 0-.75.75v8.75c0 .414.336.75.75.75z\" />\n",
      "</svg>\n",
      "</div>\n",
      "<h3 class=\"text-xl font-semibold mb-2\">Technology Hub</h3>\n",
      "<p class=\"text-gray-600 mb-4\">Stay updated with the latest in computing and IT innovations.</p>\n",
      "<ul class=\"flex flex-wrap gap-2 text-sm text-gray-500\">\n",
      "<li class=\"bg-gray-100 px-3 py-1 rounded-full\">Computers</li>\n",
      "<li class=\"bg-gray-100 px-3 py-1 rounded-full\">AI</li>\n",
      "<li class=\"bg-gray-100 px-3 py-1 rounded-full\">Reference</li>\n",
      "</ul>\n",
      "</div>\n",
      "\n",
      "<!-- Feature Card 2 -->\n",
      "<div class=\"bg-white rounded-2xl shadow-md p-6 flex flex-col\">\n",
      "<div class=\"flex items-center justify-center w-16 h-16 bg-green-100 rounded-full mb-4\">\n",
      "<!-- Example SVG: Health Icon -->\n",
      "<svg class=\"w-8 h-8 text-green-600\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\"\n",
      "viewBox=\"0 0 24 24\">\n",
      "<path stroke-linecap=\"round\" stroke-linejoin=\"round\"\n",
      "d=\"M5.121 19.121A4 4 0 1 1 2 12.828M22 12.828a4 4 0 1 1-3.121 6.293M12 14l-2-2m0 0l2-2m-2 2h8\" />\n",
      "</svg>\n",
      "</div>\n",
      "<h3 class=\"text-xl font-semibold mb-2\">Wellness Tracker</h3>\n",
      "<p class=\"text-gray-600 mb-4\">Monitor your health and improve your lifestyle with smart tools.</p>\n",
      "<ul class=\"flex flex-wrap gap-2 text-sm text-gray-500\">\n",
      "<li class=\"bg-gray-100 px-3 py-1 rounded-full\">Health</li>\n",
      "<li class=\"bg-gray-100 px-3 py-1 rounded-full\">Fitness</li>\n",
      "<li class=\"bg-gray-100 px-3 py-1 rounded-full\">Diet</li>\n",
      "</ul>\n",
      "</div>\n",
      "\n",
      "<!-- Feature Card 3 -->\n",
      "<div class=\"bg-white rounded-2xl shadow-md p-6 flex flex-col\">\n",
      "<div class=\"flex items-center justify-center w-16 h-16 bg-purple-100 rounded-full mb-4\">\n",
      "<!-- Example SVG: Book Icon -->\n",
      "<svg class=\"w-8 h-8 text-purple-600\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\"\n",
      "viewBox=\"0 0 24 24\">\n",
      "<path stroke-linecap=\"round\" stroke-linejoin=\"round\"\n",
      "d=\"M12 20.25c-4.97 0-9-1.567-9-3.5v-9.5c0-1.933 4.03-3.5 9-3.5s9 1.567 9 3.5v9.5c0 1.933-4.03 3.5-9 3.5z\" />\n",
      "</svg>\n",
      "</div>\n",
      "<h3 class=\"text-xl font-semibold mb-2\">Knowledge Base</h3>\n",
      "<p class=\"text-gray-600 mb-4\">Access a wealth of curated articles and trusted resources.</p>\n",
      "<ul class=\"flex flex-wrap gap-2 text-sm text-gray-500\">\n",
      "<li class=\"bg-gray-100 px-3 py-1 rounded-full\">Reference</li>\n",
      "<li class=\"bg-gray-100 px-3 py-1 rounded-full\">Learning</li>\n",
      "<li class=\"bg-gray-100 px-3 py-1 rounded-full\">Library</li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "</section>\n",
      "</body>\n",
      "</html>\n",
      "âœ… Features:\n",
      "Responsive Layout: Single-column on mobile, three-column on desktop (grid-cols-1 â†’ grid-cols-3)\n",
      "\n",
      "SVG Icons: Tailored for clarity and scalable design\n",
      "\n",
      "Cards: Clean, modern look with rounded-2xl, shadow-md, and flex layout\n",
      "\n",
      "Utility Styling: Fully styled using Tailwind classes â€” no extra CSS\n",
      "\n",
      "No JavaScript: Fully static and ready to drop into any HTML project\n",
      "\n",
      "Let me know if you'd like it dark-themed or with animation effects!\n",
      "\n",
      "\n",
      "Response B:\n",
      "<div class=\"bg-gray-100 py-12\">\n",
      "<div class=\"max-w-6xl mx-auto px-4 sm:px-6 lg:px-8\">\n",
      "<div class=\"text-center\">\n",
      "<h2 class=\"text-3xl font-extrabold text-gray-900 sm:text-4xl\">\n",
      "Explore Our Amazing Features\n",
      "</h2>\n",
      "<p class=\"mt-3 text-lg text-gray-500 sm:mt-4\">\n",
      "Discover how our platform can help you achieve your goals with these powerful features.\n",
      "</p>\n",
      "</div>\n",
      "<div class=\"mt-10 grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8\">\n",
      "<div class=\"bg-white rounded-lg shadow-lg overflow-hidden\">\n",
      "<div class=\"p-6 flex flex-col items-center\">\n",
      "<svg class=\"w-12 h-12 text-indigo-500 mb-4\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n",
      "<path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M9.75 17L9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14m-9-9h4m-2-2h2m-2-4h2\" />\n",
      "</svg>\n",
      "<h3 class=\"text-xl font-semibold text-gray-800 mb-2 text-center\">Intuitive Interface</h3>\n",
      "<p class=\"text-gray-600 text-center mb-4\">\n",
      "Our user-friendly design makes navigation a breeze, allowing you to focus on what matters most.\n",
      "</p>\n",
      "<ul class=\"flex space-x-2\">\n",
      "<li><span class=\"inline-block bg-indigo-100 text-indigo-800 text-xs font-semibold rounded-full px-2 py-1\">Computers</span></li>\n",
      "<li><span class=\"inline-block bg-indigo-100 text-indigo-800 text-xs font-semibold rounded-full px-2 py-1\">Usability</span></li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "\n",
      "<div class=\"bg-white rounded-lg shadow-lg overflow-hidden\">\n",
      "<div class=\"p-6 flex flex-col items-center\">\n",
      "<svg class=\"w-12 h-12 text-green-500 mb-4\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n",
      "<path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M12 6.253v13m0-13C10.832 5.477 9.246 5 7.5 5S4.168 5.477 3 6.253v13C4.168 18.523 5.754 18 7.5 18s3.332.477 4.5 1.253m0-13C13.168 5.477 14.754 5 16.5 5S18.832 5.477 20 6.253v13C18.832 18.523 17.246 18 15.5 18s-3.332.477-4.5 1.253\" />\n",
      "</svg>\n",
      "<h3 class=\"text-xl font-semibold text-gray-800 mb-2 text-center\">Robust Performance</h3>\n",
      "<p class=\"text-gray-600 text-center mb-4\">\n",
      "Experience seamless operation and reliable performance even under heavy load.\n",
      "</p>\n",
      "<ul class=\"flex space-x-2\">\n",
      "<li><span class=\"inline-block bg-green-100 text-green-800 text-xs font-semibold rounded-full px-2 py-1\">Technology</span></li>\n",
      "<li><span class=\"inline-block bg-green-100 text-green-800 text-xs font-semibold rounded-full px-2 py-1\">Efficiency</span></li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "\n",
      "<div class=\"bg-white rounded-lg shadow-lg overflow-hidden\">\n",
      "<div class=\"p-6 flex flex-col items-center\">\n",
      "<svg class=\"w-12 h-12 text-blue-500 mb-4\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n",
      "<path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z\" />\n",
      "</svg>\n",
      "<h3 class=\"text-xl font-semibold text-gray-800 mb-2 text-center\">Dedicated Support</h3>\n",
      "<p class=\"text-gray-600 text-center mb-4\">\n",
      "Our expert support team is always ready to assist you with any questions or issues you may encounter.\n",
      "</p>\n",
      "<ul class=\"flex space-x-2\">\n",
      "<li><span class=\"inline-block bg-blue-100 text-blue-800 text-xs font-semibold rounded-full px-2 py-1\">Reference</span></li>\n",
      "<li><span class=\"inline-block bg-blue-100 text-blue-800 text-xs font-semibold rounded-full px-2 py-1\">Help</span></li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Response C:\n",
      "To create a responsive feature section with the specified requirements using TailwindCSS,\n",
      "we will structure the HTML code to include the main heading, short description, and three feature cards.\n",
      "Each feature card will contain an SVG icon, a title, a description, and a list of related topics.\n",
      "We will use a grid system for layout and flexbox for alignment, styled entirely with Tailwind utility classes to\n",
      "ensure responsiveness.\n",
      "Here is the complete HTML code for the responsive feature section:\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "\n",
      "<head>\n",
      "<meta charset=\"UTF-8\">\n",
      "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "<title>Responsive Feature Section</title>\n",
      "<link href=\"https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css\" rel=\"stylesheet\">\n",
      "</head>\n",
      "\n",
      "<body class=\"bg-gray-100 min-h-screen flex flex-col items-center justify-center py-8\">\n",
      "<div class=\"max-w-screen-lg w-full px-4\">\n",
      "<h1 class=\"text-4xl font-bold text-center mb-6\">Main Heading</h1>\n",
      "<p class=\"text-lg text-center text-gray-600 mb-8\">Short Description</p>\n",
      "<div class=\"grid grid-cols-1 md:grid-cols-3 gap-4\">\n",
      "<!-- Feature Card 1 -->\n",
      "<div class=\"bg-white rounded-lg p-6 shadow-md\">\n",
      "<div class=\"text-center\">\n",
      "<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"h-12 w-12 mx-auto mb-4\" viewBox=\"0 0 20 20\"\n",
      "fill=\"currentColor\">\n",
      "<path\n",
      "d=\"M2 3a1 1 0 0 1 1-1h3.586a1 1 0 0 1 .707.293l9 9a1 1 0 0 1 .004 1.396l-6 6a1 1 0 0 1-1.392-.008l-4.954-5.64L5.414 12.01l3.293 3.293 5.325-5.768a.947.947 0 0 1 1.364.003l4 4a.997.997 0 0 1-.001 1.387l-9 9a.999.999 0 0 1-1.427.002l-10-10A1 1 0 0 1 2 13V3z\" />\n",
      "</svg>\n",
      "<h2 class=\"text-xl font-bold mb-2\">Feature Title 1</h2>\n",
      "<p class=\"text-gray-600\">Feature Description 1</p>\n",
      "<ul class=\"text-sm text-gray-500 mt-4\">\n",
      "<li>Computers</li>\n",
      "<li>Health</li>\n",
      "<li>Reference</li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "<!-- Feature Card 2 -->\n",
      "<div class=\"bg-white rounded-lg p-6 shadow-md\">\n",
      "<div class=\"text-center\">\n",
      "<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"h-10 w-10 mx-auto mb-4\" viewBox=\"0 0 20 20\"\n",
      "fill=\"currentColor\">\n",
      "<!-- Add SVG Path for the icon -->\n",
      "</svg>\n",
      "<h2 class=\"text-xl font-bold mb-2\">Feature Title 2</h2>\n",
      "<p class=\"text-gray-600\">Feature Description 2</p>\n",
      "<ul class=\"text-sm text-gray-500 mt-4\">\n",
      "<li>Computers</li>\n",
      "<li>Health</li>\n",
      "<li>Reference</li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "<!-- Feature Card 3 -->\n",
      "<div class=\"bg-white rounded-lg p-6 shadow-md\">\n",
      "<div class=\"text-center\">\n",
      "<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"h-10 w-10 mx-auto mb-4\" viewBox=\"0 0 20 20\"\n",
      "fill=\"currentColor\">\n",
      "<!-- Add SVG Path for the icon -->\n",
      "</svg>\n",
      "<h2 class=\"text-xl font-bold mb-2\">Feature Title 3</h2>\n",
      "<p class=\"text-gray-600\">Feature Description 3</p>\n",
      "<ul class=\"text-sm text-gray-500 mt-4\">\n",
      "<li>Computers</li>\n",
      "<li>Health</li>\n",
      "<li>Reference</li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</body>\n",
      "\n",
      "</html>\n",
      "\n",
      "In this code:\n",
      "- The main heading, description, and three feature cards are included within a structured layout using TailwindCSS utility classes.\n",
      "- Each feature card contains an SVG icon, title, description, and a list of related topics (Computers, Health, Reference).\n",
      "- The grid system and flexbox are used for responsive design and alignment.\n",
      "- TailwindCSS classes are utilized for styling elements such as spacing, typography, shadows, and rounded corners to achieve a clean and modern design.\n",
      "You can copy and paste this code into an HTML file to create the responsive feature section as described.\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt\n",
    "prompt = \"Can you generate an HTML code using TailwindCSS that creates a responsive feature section with a main heading, a short description, and three feature cards? Each card should include an SVG icon, a title, a description, and a list of related topics (like Computers, Health, Reference). The layout should use a grid system and flexbox for alignment, styled entirely with Tailwind utility classes. It should have a clean, modern design and be fully responsive. This component should be static, with no JavaScript interactivity.\"\n",
    "\n",
    "# Read responses from a text file\n",
    "def read_responses_from_text_file(file_path):\n",
    "    try:\n",
    "        responses = {}\n",
    "        current_response = None\n",
    "        response_content = []\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                \n",
    "                # Check if this is a response identifier line (e.g., \"Response A:\")\n",
    "                if line.endswith(':') and line.startswith('Response '):\n",
    "                    # If we were already processing a response, save it\n",
    "                    if current_response:\n",
    "                        responses[current_response] = '\\n'.join(response_content)\n",
    "                    \n",
    "                    # Start new response\n",
    "                    current_response = line[:-1]  # Remove the colon\n",
    "                    response_content = []\n",
    "                \n",
    "                # Otherwise add to current response content if we're in a response section\n",
    "                elif current_response:\n",
    "                    response_content.append(line)\n",
    "            \n",
    "            # Add the last response if there is one\n",
    "            if current_response and response_content:\n",
    "                responses[current_response] = '\\n'.join(response_content)\n",
    "                \n",
    "        return responses\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {file_path} not found.\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "file_path = \"responses.txt\"\n",
    "responses = read_responses_from_text_file(file_path)\n",
    "\n",
    "if responses:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(\"\\nResponses:\")\n",
    "    for key, value in responses.items():\n",
    "        print(f\"\\n{key}:\")\n",
    "        print(value)\n",
    "        \n",
    "        \n",
    "# Define the prompt and three responses\n",
    "# prompt = \"Your specific prompt here\"\n",
    "# responses = {\n",
    "#     'Response A': \"First RAG response\",\n",
    "#     'Response B': \"Second RAG response\",\n",
    "#     'Response C': \"Third RAG response\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Semantic Similarity Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12536\\3818835164.py:7: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  return doc1.similarity(doc2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Similarity Scores:\n",
      "Response A: 0.2206\n",
      "Response B: 0.2029\n",
      "Response C: 0.2664\n"
     ]
    }
   ],
   "source": [
    "def semantic_similarity(text1, text2):\n",
    "    \"\"\"\n",
    "    Calculate semantic similarity using spaCy word embeddings\n",
    "    \"\"\"\n",
    "    doc1 = nlp(text1)\n",
    "    doc2 = nlp(text2)\n",
    "    return doc1.similarity(doc2)\n",
    "\n",
    "# Semantic similarity to the prompt\n",
    "semantic_scores = {}\n",
    "for name, response in responses.items():\n",
    "    semantic_scores[name] = semantic_similarity(prompt, response)\n",
    "\n",
    "print(\"Semantic Similarity Scores:\")\n",
    "for name, score in semantic_scores.items():\n",
    "    print(f\"{name}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ROUGE Score Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores:\n",
      "Response A:\n",
      "  ROUGE-1: 0.1298\n",
      "  ROUGE-2: 0.0441\n",
      "  ROUGE-L: 0.0718\n",
      "Response B:\n",
      "  ROUGE-1: 0.0387\n",
      "  ROUGE-2: 0.0000\n",
      "  ROUGE-L: 0.0277\n",
      "Response C:\n",
      "  ROUGE-1: 0.1818\n",
      "  ROUGE-2: 0.1290\n",
      "  ROUGE-L: 0.1371\n"
     ]
    }
   ],
   "source": [
    "# ROUGE Score Calculation\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "rouge_scores = {}\n",
    "for name, response in responses.items():\n",
    "    rouge_scores[name] = scorer.score(prompt, response)\n",
    "\n",
    "print(\"ROUGE Scores:\")\n",
    "for name, scores in rouge_scores.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  ROUGE-1: {scores['rouge1'].fmeasure:.4f}\")\n",
    "    print(f\"  ROUGE-2: {scores['rouge2'].fmeasure:.4f}\")\n",
    "    print(f\"  ROUGE-L: {scores['rougeL'].fmeasure:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perplexity Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity Scores:\n",
      "Response A: 17.0156\n",
      "Response B: 15.2050\n",
      "Response C: 23.2467\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Function to read responses from a text file\n",
    "def read_responses_from_file(file_path):\n",
    "    try:\n",
    "        responses = {}\n",
    "        current_response = None\n",
    "        response_content = []\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                \n",
    "                # Check if this is a response identifier line (e.g., \"Response A:\")\n",
    "                if line.endswith(':') and line.startswith('Response '):\n",
    "                    # If we were already processing a response, save it\n",
    "                    if current_response:\n",
    "                        responses[current_response] = '\\n'.join(response_content)\n",
    "                    \n",
    "                    # Start new response\n",
    "                    current_response = line[:-1]  # Remove the colon\n",
    "                    response_content = []\n",
    "                \n",
    "                # Otherwise add to current response content if we're in a response section\n",
    "                elif current_response:\n",
    "                    response_content.append(line)\n",
    "            \n",
    "            # Add the last response if there is one\n",
    "            if current_response and response_content:\n",
    "                responses[current_response] = '\\n'.join(response_content)\n",
    "                \n",
    "        return responses\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {file_path} not found.\")\n",
    "        return None\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "def calculate_perplexity(text, max_length=1024):\n",
    "    \"\"\"\n",
    "    Calculate perplexity of the text with chunking for long texts\n",
    "    Lower perplexity indicates better language model performance\n",
    "    \"\"\"\n",
    "    # Handle text that's too long by chunking\n",
    "    if len(text) > 3000:  # An arbitrary threshold\n",
    "        chunks = []\n",
    "        words = text.split()\n",
    "        chunk = []\n",
    "        chunk_length = 0\n",
    "        \n",
    "        for word in words:\n",
    "            chunk.append(word)\n",
    "            chunk_length += len(word) + 1  # +1 for space\n",
    "            \n",
    "            if chunk_length > 1000:  # Smaller than max_length to be safe\n",
    "                chunks.append(' '.join(chunk))\n",
    "                chunk = []\n",
    "                chunk_length = 0\n",
    "        \n",
    "        # Add the last chunk if it exists\n",
    "        if chunk:\n",
    "            chunks.append(' '.join(chunk))\n",
    "        \n",
    "        # Calculate perplexity for each chunk and average\n",
    "        perplexities = []\n",
    "        for chunk_text in chunks:\n",
    "            # Prepare the input\n",
    "            encodings = tokenizer(chunk_text, return_tensors='pt', truncation=True, max_length=max_length)\n",
    "            \n",
    "            # Calculate loss\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**encodings, labels=encodings['input_ids'])\n",
    "                loss = outputs.loss\n",
    "            \n",
    "            # Calculate perplexity\n",
    "            perplexity = torch.exp(loss).item()\n",
    "            perplexities.append(perplexity)\n",
    "        \n",
    "        return sum(perplexities) / len(perplexities)\n",
    "    else:\n",
    "        # Prepare the input\n",
    "        encodings = tokenizer(text, return_tensors='pt', truncation=True, max_length=max_length)\n",
    "        \n",
    "        # Calculate loss\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encodings, labels=encodings['input_ids'])\n",
    "            loss = outputs.loss\n",
    "        \n",
    "        # Calculate perplexity\n",
    "        perplexity = torch.exp(loss).item()\n",
    "        return perplexity\n",
    "\n",
    "# Example usage\n",
    "file_path = \"responses.txt\"\n",
    "responses = read_responses_from_file(file_path)\n",
    "\n",
    "if responses:\n",
    "    # Calculate perplexity for each response\n",
    "    perplexity_scores = {}\n",
    "    for name, response in responses.items():\n",
    "        perplexity_scores[name] = calculate_perplexity(response)\n",
    "    \n",
    "    print(\"Perplexity Scores:\")\n",
    "    for name, score in perplexity_scores.items():\n",
    "        print(f\"{name}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embedding-based Bias Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Admin/nltk_data'\n    - 'c:\\\\ITITIU20316\\\\THESIS\\\\ROUGE\\\\THESIS_EVALUATION\\\\.venv\\\\nltk_data'\n    - 'c:\\\\ITITIU20316\\\\THESIS\\\\ROUGE\\\\THESIS_EVALUATION\\\\.venv\\\\share\\\\nltk_data'\n    - 'c:\\\\ITITIU20316\\\\THESIS\\\\ROUGE\\\\THESIS_EVALUATION\\\\.venv\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Admin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m bias_scores = {}\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, response \u001b[38;5;129;01min\u001b[39;00m responses.items():\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     bias_scores[name] = \u001b[43mcalculate_word_embedding_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_terms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBias Scores:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, score \u001b[38;5;129;01min\u001b[39;00m bias_scores.items():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mcalculate_word_embedding_bias\u001b[39m\u001b[34m(text, bias_terms)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03mCalculate bias in word embeddings\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Tokenize the text\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m tokens = \u001b[43mnltk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Calculate average similarity to bias terms\u001b[39;00m\n\u001b[32m     14\u001b[39m bias_scores = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ITITIU20316\\THESIS\\ROUGE\\THESIS_EVALUATION\\.venv\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:142\u001b[39m, in \u001b[36mword_tokenize\u001b[39m\u001b[34m(text, language, preserve_line)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mword_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m, preserve_line=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    128\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[33;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m \u001b[33;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     sentences = [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    144\u001b[39m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer.tokenize(sent)\n\u001b[32m    145\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ITITIU20316\\THESIS\\ROUGE\\THESIS_EVALUATION\\.venv\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:119\u001b[39m, in \u001b[36msent_tokenize\u001b[39m\u001b[34m(text, language)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msent_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    110\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[33;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m \u001b[33;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     tokenizer = \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer.tokenize(text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ITITIU20316\\THESIS\\ROUGE\\THESIS_EVALUATION\\.venv\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:105\u001b[39m, in \u001b[36m_get_punkt_tokenizer\u001b[39m\u001b[34m(language)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_punkt_tokenizer\u001b[39m(language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     98\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m    a lru cache for performance.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m    :type language: str\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ITITIU20316\\THESIS\\ROUGE\\THESIS_EVALUATION\\.venv\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[39m, in \u001b[36mPunktTokenizer.__init__\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1743\u001b[39m     PunktSentenceTokenizer.\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1744\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ITITIU20316\\THESIS\\ROUGE\\THESIS_EVALUATION\\.venv\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[39m, in \u001b[36mPunktTokenizer.load_lang\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1746\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1747\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[32m-> \u001b[39m\u001b[32m1749\u001b[39m     lang_dir = \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;28mself\u001b[39m._params = load_punkt_params(lang_dir)\n\u001b[32m   1751\u001b[39m     \u001b[38;5;28mself\u001b[39m._lang = lang\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ITITIU20316\\THESIS\\ROUGE\\THESIS_EVALUATION\\.venv\\Lib\\site-packages\\nltk\\data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    577\u001b[39m sep = \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Admin/nltk_data'\n    - 'c:\\\\ITITIU20316\\\\THESIS\\\\ROUGE\\\\THESIS_EVALUATION\\\\.venv\\\\nltk_data'\n    - 'c:\\\\ITITIU20316\\\\THESIS\\\\ROUGE\\\\THESIS_EVALUATION\\\\.venv\\\\share\\\\nltk_data'\n    - 'c:\\\\ITITIU20316\\\\THESIS\\\\ROUGE\\\\THESIS_EVALUATION\\\\.venv\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Admin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Load pre-trained word vectors\n",
    "word_vectors = api.load('glove-wiki-gigaword-100')\n",
    "\n",
    "def calculate_word_embedding_bias(text, bias_terms):\n",
    "    \"\"\"\n",
    "    Calculate bias in word embeddings\n",
    "    \"\"\"\n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    \n",
    "    # Calculate average similarity to bias terms\n",
    "    bias_scores = []\n",
    "    for term in bias_terms:\n",
    "        term_similarities = []\n",
    "        for token in tokens:\n",
    "            if token in word_vectors.key_to_index:\n",
    "                try:\n",
    "                    similarity = word_vectors.similarity(token, term)\n",
    "                    term_similarities.append(similarity)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        \n",
    "        # Average similarity for this bias term\n",
    "        if term_similarities:\n",
    "            bias_scores.append(np.mean(term_similarities))\n",
    "    \n",
    "    # Overall bias score\n",
    "    return np.mean(bias_scores) if bias_scores else 0\n",
    "\n",
    "# Define bias terms (these should be chosen carefully)\n",
    "bias_terms = ['man', 'woman', 'he', 'she', 'male', 'female']\n",
    "\n",
    "# Calculate bias for each response\n",
    "bias_scores = {}\n",
    "for name, response in responses.items():\n",
    "    bias_scores[name] = calculate_word_embedding_bias(response, bias_terms)\n",
    "\n",
    "print(\"Bias Scores:\")\n",
    "for name, score in bias_scores.items():\n",
    "    print(f\"{name}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comprehensive Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all evaluation metrics\n",
    "evaluation_summary = pd.DataFrame({\n",
    "    'Semantic Similarity': semantic_scores,\n",
    "    'ROUGE-1 Score': {name: scores['rouge1'].fmeasure for name, scores in rouge_scores.items()},\n",
    "    'ROUGE-2 Score': {name: scores['rouge2'].fmeasure for name, scores in rouge_scores.items()},\n",
    "    'Perplexity': perplexity_scores,\n",
    "    'Embedding Bias': bias_scores\n",
    "})\n",
    "\n",
    "print(\"Comprehensive Evaluation Summary:\")\n",
    "print(evaluation_summary)\n",
    "\n",
    "# Normalize and weight different metrics\n",
    "def normalize_column(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "# Weights for different metrics (adjust as needed)\n",
    "weights = {\n",
    "    'Semantic Similarity': 0.25,\n",
    "    'ROUGE-1 Score': 0.2,\n",
    "    'ROUGE-2 Score': 0.2,\n",
    "    'Perplexity': -0.2,  # Negative weight as lower is better\n",
    "    'Embedding Bias': -0.15  # Negative weight as less bias is better\n",
    "}\n",
    "\n",
    "# Normalize and weight the scores\n",
    "weighted_scores = {}\n",
    "for column, weight in weights.items():\n",
    "    normalized = normalize_column(evaluation_summary[column])\n",
    "    for name in responses.keys():\n",
    "        if name not in weighted_scores:\n",
    "            weighted_scores[name] = 0\n",
    "        weighted_scores[name] += normalized[name] * weight\n",
    "\n",
    "# Print final ranking\n",
    "print(\"\\nFinal Weighted Scores:\")\n",
    "for name, score in sorted(weighted_scores.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{name}: {score:.4f}\")\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(weighted_scores.keys(), weighted_scores.values())\n",
    "plt.title('Comprehensive RAG Response Evaluation')\n",
    "plt.xlabel('Response')\n",
    "plt.ylabel('Weighted Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provides a comprehensive evaluation of RAG ChatBot responses using multiple metrics:\n",
    "\n",
    "1. Semantic Similarity\n",
    "2. ROUGE Scores\n",
    "3. Perplexity\n",
    "4. Embedding-based Bias Evaluation\n",
    "\n",
    "The final weighted score considers the performance across these different dimensions, providing a holistic assessment of the responses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
